services:
  mcp-proxy:
    build: .
    ports:
      - "8009:8009"
    # On Linux, use host network mode to access host services
    # Comment out 'network_mode: host' and use 'extra_hosts' on Mac/Windows
    network_mode: host
    # extra_hosts:
    #   - "host.docker.internal:host-gateway"
    environment:
      # Required: Set your upstream MCP server URL
      # Use localhost when network_mode: host
      - MCP_UPSTREAM_URL=http://localhost:8931/mcp

      # Optional: LLM configuration for summarization
      # If not set, proxy runs in pass-through mode
      - BASE_URL=http://localhost:8000/v1
      - MODEL_NAME=openai/gpt-oss-120b
      - API_KEY=EMPTY

      # Proxy configuration
      - MCP_PROXY_CONFIG_FILE=test_proxy_config.json
      - HOST=0.0.0.0
      - PORT=8002
      - LOG_LEVEL=INFO

    # Mount custom config
    volumes:
      - ./test_proxy_config.json:/app/test_proxy_config.json:ro

    restart: unless-stopped
